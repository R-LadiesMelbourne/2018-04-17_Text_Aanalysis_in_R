"txt","filename"
"April 4, 2018  An Update on Our Plans to Restrict Data Access on Facebook By Mike Schroepfer, Chief Technology Officer  Two weeks ago we promised to take a hard look at the information apps can use when you connect them to Facebook as well as other data practices. Today, we want to update you on the changes we’re making to better protect your Facebook information. We expect to make more changes over the coming months — and will keep you updated on our progress. Here are the details of the nine most important changes we are making.  Events API: Until today, people could grant an app permission to get information about events they host or attend, including private events. This made it easy to add Facebook Events to calendar, ticketing or other apps. But Facebook Events have information about other people’s attendance as well as posts on the event wall, so it’s important that we ensure apps use their access appropriately. Starting today, apps using the API will no longer be able to access the guest list or posts on the event wall. And in the future, only apps we approve that agree to strict requirements will be allowed to use the Events API.  Groups API: Currently apps need the permission of a group admin or member to access group content for closed groups, and the permission of an admin for secret groups. These apps help admins do things like easily post and respond to content in their groups. However, there is information about people and conversations in groups that we want to make sure is better protected. Going forward, all third-party apps using the Groups API will need approval from Facebook and an admin to ensure they benefit the group. Apps will no longer be able to access the member list of a group. And we’re also removing personal information, such as names and profile photos, attached to posts or comments that approved apps can access.  Pages API: Until today, any app could use the Pages API to read posts or comments from any Page. This let developers create tools for Page owners to help them do things like schedule posts and reply to comments or messages. But it also let apps access more data than necessary. We want to make sure Page information is only available to apps providing useful services to our community. So starting today, all future access to the Pages API will need to be approved by Facebook.  Facebook Login: Two weeks ago we announced important changes to Facebook Login. Starting today, Facebook will need to approve all apps that request access to information such as check-ins, likes, photos, posts, videos, events and groups. We started approving these permissions in 2014, but now we’re tightening our review process — requiring these apps to agree to strict requirements before they can access this data. We will also no longer allow apps to ask for access to personal information such as religious or political views, relationship status and details, custom friends lists, education and work history, fitness activity, book reading activity, music listening activity, news reading, video watch activity, and games activity. In the next week, we will remove a developer’s ability to request data people shared with them if it appears they have not used the app in the last 3 months.  Instagram Platform API: We’re making the recently announced deprecation of the Instagram Platform API effective today. You can find more information here.  Search and Account Recovery: Until today, people could enter another person’s phone number or email address into Facebook search to help find them. This has been especially useful for finding your friends in languages which take more effort to type out a full name, or where many people have the same name. In Bangladesh, for example, this feature makes up 7% of all searches. However, malicious actors have also abused these features to scrape public profile information by submitting phone numbers or email addresses they already have through search and account recovery. Given the scale and sophistication of the activity we’ve seen, we believe most people on Facebook could have had their public profile scraped in this way. So we have now disabled this feature. We’re also making changes to account recovery to reduce the risk of scraping as well.  Call and Text History: Call and text history is part of an opt-in feature for people using Messenger or Facebook Lite on Android. This means we can surface the people you most frequently connect with at the top of your contact list. We’ve reviewed this feature to confirm that Facebook does not collect the content of messages — and will delete all logs older than one year. In the future, the client will only upload to our servers the information needed to offer this feature — not broader data such as the time of calls.  Data Providers and Partner Categories: Last week we announced our plans to shut down Partner Categories, a product that lets third-party data providers offer their targeting directly on Facebook.  App Controls: Finally, starting on Monday, April 9, we’ll show people a link at the top of their News Feed so they can see what apps they use — and the information they have shared with those apps. People will also be able to remove apps that they no longer want. As part of this process we will also tell people if their information may have been improperly shared with Cambridge Analytica.   Updated April 9, 2017: Three versions of the messages we’re sending to people based on whether they’ve been affected by the app “This Is Your Digital Life.” These messages link to facebook.com/help/yourinfo.  In total, we believe the Facebook information of up to 87 million people — mostly in the US — may have been improperly shared with Cambridge Analytica.    Overall, we believe these changes will better protect people’s information while still enabling developers to create useful experiences. We know we have more work to do — and we’ll keep you updated as we make more changes. You can find more details on the platform changes in our Facebook Developer Blog.","data/Facebook newsroom/An Update on Our Plans to Restrict Data Access on Facebook.txt"
"April 3, 2018  Authenticity Matters: The IRA Has No Place on Facebook By Alex Stamos, Chief Security Officer  This morning we removed 70 Facebook and 65 Instagram accounts — as well as 138 Facebook Pages — that were controlled by the Russia-based Internet Research Agency (IRA). Many of the Pages also ran ads, all of which have been removed. Of the Pages that had content, the vast majority of them (95%) were in Russian — targeted either at people living in Russia or Russian-speakers around the world including from neighboring countries like Azerbaijan, Uzbekistan and Ukraine.    Uncovering this activity took months of work by our team and I wanted to explain why we took this action.  Facebook was built for conversation and human connection. It’s why we ask that people using our service be themselves — whether it’s an individual, a business or a nonprofit. Of course this isn’t always possible. Many human rights activists, for example, have to hide their true identities to stay safe. But we’ve worked hard to establish authenticity as a social norm because it’s at the heart of most meaningful connections on Facebook.  The IRA has repeatedly used complex networks of inauthentic accounts to deceive and manipulate people who use Facebook, including before, during and after the 2016 US presidential elections. It’s why we don’t want them on Facebook. We removed this latest set of Pages and accounts solely because they were controlled by the IRA — not based on the content. This included commentary on domestic and international political issues, the promotion of Russian culture and tourism as well as debate on more everyday issues. Given the interest in the IRA, we’re releasing a sample of the Page posts and ads:    We’d like to share more — and we’re looking into the best way to provide more transparency into what the IRA has done. In the next few weeks, we’ll be updating our Help Center tool so anyone can check if they liked or followed one of these Pages.  The IRA has consistently used inauthentic accounts to deceive and manipulate people. It’s why we remove every account we find that is linked to the organization — whether linked to activity in the US, Russia or elsewhere. We know that the IRA — and other bad actors seeking to abuse Facebook — are always changing their tactics to hide from our security team. We expect we will find more, and if we do we will take them down too. But we’ll keep fighting and we’re investing heavily in more people and better technology to constantly improve safety on Facebook.","data/Facebook newsroom/Authenticity Matters.txt"
"March 6, 2018  Catalyst Housing Fund Attracts New Investor By Elliot Schrage, VP Corporate Communications & Public Policy  Silicon Valley has a remarkable energy that makes it a great place to live and work. Though the region is thriving in many ways, our community clearly needs more affordable places to live. That’s why we’re working alongside our neighbors to increase affordable housing in the Bay Area.  In 2016, we announced a partnership with Envision Transform Build and the cities of East Palo Alto and Menlo Park to create regional solutions to the affordable housing crisis. A pillar of the partnership was to create the Catalyst Housing Fund with an initial investment of $18.5 million to pursue innovative and scalable ways to increase the construction and protection of affordable housing. In August 2017, we announced Local Initiatives Support Corporation and Housing Trust Silicon Valley would manage the fund and leverage our initial investment to as much as $75 million.  New partners will help solve the housing crisis through this unique partnership. Today, we are pleased to announce The San Francisco Foundation (TSFF) is contributing $1 million to the Catalyst Housing Fund.  With more than $1.4 billion in assets, The San Francisco Foundation (TSFF) is one of the largest community foundations in the country. For 70 years, the foundation has been dedicated to serving the Bay Area in its many roles — civic leader, advocate, grantmaker, philanthropic partner, and convener. The foundation has a long history in affordable housing; and through its grantmaking pathways — People, Place, and Power — the foundation is working to ensure that everyone has a chance at full employment, a safe and affordable home, and a strong political voice.  Its grantmaking strategy focuses on racial and economic equity by organizing its work in three pathways: People, Place, Power. These pathways align with the pillars of our community partnership.  We aim to deploy funds in the next five to eight years to accelerate the development of affordable housing in the region. But we’re not waiting until construction starts to make a difference. Since the announcement of the community partnership, the partners have provided $500,000 to Community Legal Services in East Palo Alto (CLSEPA) to support Belle Haven and East Palo Alto residents threatened with displacement from evictions or abuse by landlords. The partners have also contributed $250,000 to Rebuilding Together Peninsula to rehabilitate and reconstruct homes in East Palo Alto and Belle Haven.  Through the partnership, we will also address what we can do to increase economic opportunity for our neighbors. For example, last October, we partnered with career and vocational training nonprofit JobTrain to support its apprenticeship program and pair future graduates with jobs on our active construction projects.  Our mission to give people the power to build community has to begin at home in Menlo Park and the surrounding cities. TSFF’s generous investment and the support of new partners will help us continue to support building economic opportunity in Silicon Valley and create regional solutions for affordable housing.","data/Facebook newsroom/Catalyst Housing Fund Attracts New Investor.txt"
"March 21, 2018  Cracking Down on Platform Abuse Protecting people’s information is the most important thing we do at Facebook. What happened with Cambridge Analytica was a breach of Facebook’s trust. More importantly, it was a breach of the trust people place in Facebook to protect their data when they share it. As Mark Zuckerberg explained in his post, we are announcing some important steps for the future of our platform. These steps involve taking action on potential past abuse and putting stronger protections in place to prevent future abuse.  People use Facebook to connect with friends and others using all kinds of apps. Facebook’s platform helped make apps social — so your calendar could show your friends’ birthdays, for instance. To do this, we allowed people to log into apps and share who their friends were and some information about them.  As people used the Facebook platform in new ways, we strengthened the rules. We required that developers get people’s permission before they access the data needed to run their apps – for instance, a photo sharing app has to get specific permission from you to access your photos. Over the years we’ve introduced more guardrails, including in 2014, when we began reviewing apps that request certain data before they could launch, and introducing more granular controls for people to decide what information to share with apps. These actions would prevent any app like Aleksandr Kogan’s from being able to access so much data today.  Even with these changes, we’ve seen abuse of our platform and the misuse of people’s data, and we know we need to do more. We have a responsibility to everyone who uses Facebook to make sure their privacy is protected. That’s why we’re making changes to prevent abuse. We’re going to set a higher standard for how developers build on Facebook, what people should expect from them, and, most importantly, from us. We will:  Review our platform. We will investigate all apps that had access to large amounts of information before we changed our platform in 2014 to reduce data access, and we will conduct a full audit of any app with suspicious activity. If we find developers that misused personally identifiable information, we will ban them from our platform. Tell people about data misuse. We will tell people affected by apps that have misused their data. This includes building a way for people to know if their data might have been accessed via “thisisyourdigitallife.” Moving forward, if we remove an app for misusing data, we will tell everyone who used it. Turn off access for unused apps. If someone hasn’t used an app within the last three months, we will turn off the app’s access to their information. Restrict Facebook Login data. We are changing Login, so that in the next version, we will reduce the data that an app can request without app review to include only name, profile photo and email address. Requesting any other data will require our approval. Encourage people to manage the apps they use. We already show people what apps their accounts are connected to and control what data they’ve permitted those apps to use. Going forward, we’re going to make these choices more prominent and easier to manage. Reward people who find vulnerabilities. In the coming weeks we will expand Facebook’s bug bounty program so that people can also report to us if they find misuses of data by app developers. There’s more work to do, and we’ll be sharing details in the coming weeks about additional steps we’re taking to put people more in control of their data. Some of these updates were already in the works, and some are related to new data protection laws coming into effect in the EU. This week’s events have accelerated our efforts, and these changes will be the first of many we plan to roll out to protect people’s information and make our platform safer.","data/Facebook newsroom/Cracking Down on Platform Abuse.txt"
"April 10, 2018  Data Abuse Bounty: Facebook Now Rewards for Reports of Data Abuse By Collin Greene, Head of Product Security  Today, Facebook is launching the Data Abuse Bounty to reward people who report any misuse of data by app developers.  We committed to launching this program a few weeks ago as part of our efforts to more quickly uncover potential abuse of people’s information. The Data Abuse Bounty, inspired by the existing bug bounty program that we use to uncover and address security issues, will help us identify violations of our policies.    This program will reward people with first-hand knowledge and proof of cases where a Facebook platform app collects and transfers people’s data to another party to be sold, stolen or used for scams or political influence. Just like the bug bounty program, we will reward based on the impact of each report. While there is no maximum, high impact bug reports have garnered as much as $40,000 for people who bring them to our attention.  We’ll review all legitimate reports and respond as quickly as possible when we identify a credible threat to people’s information. If we confirm data abuse, we will shut down the offending app and take legal action against the company selling or buying the data, if necessary. We’ll pay the person who reported the issue, and we’ll also alert those we believe to be affected.  This program is the first of its kind so it will change as we learn and get your feedback. For more information, please visit: facebook.com/data-abuse","data/Facebook newsroom/Data Abuse Bounty.txt"
"April 3, 2018  Facebook Community Boost Partners with Houston Organizations  By Katherine Shappley, VP North America SMB  Today, we’re in Houston, the second stop of Facebook Community Boost, offering trainings to help local small businesses grow and equip entrepreneurs with digital skills.  For Community Boost to truly serve its purpose, it’s important that opportunities for education are available long after this week’s event. That’s why we’re partnering with local organizations including, Houston Area Urban League, BakerRipley, Flatiron School and WeWork to provide continued training for small businesses and job seekers here in the greater Houston area.  We’re inspired by the strength and resilience of the people of Houston especially in the wake of adversities faced this past year. And we are proud to work with these organizations to help give local businesses the tools they need to grow their business, create jobs and strengthen the local economy.  Digital Skills and Marketing Training for Houston  Every community is different, which is why we surveyed hundreds of local residents to understand the unique needs of individuals and businesses in the Houston community and tailor the program accordingly.  Small businesses and job seekers in the Houston community told us that there is a gap between the digital skills they have compared to what they need to succeed:  90% of small business managers believe that digital advertising is an important skill for growing their business, but only 20% of managers rate themselves as excellent in this area. 95% of jobs/skills seekers say digital skills are important when looking for job, but only 15% rate their digital skills as excellent. As part of our partnership, Houston Area Urban League and community organizations like BakerRipley will equip their teams to run workshops and deliver digital marketing and social media curriculum across the greater Houston area to help close these gaps long after the Community Boost event ends.  Coding Bootcamps and Workforce Development  We are sponsoring a Facebook Bootcamp with Flatiron School that will fund scholarships for a full class of its 15-week coding bootcamp at its new Houston campus at WeWork. As a part of the program, students will utilize Flatiron School’s Career Services Framework which provides dedicated career coaches who mentor students through the job search process to ensure they successfully land jobs upon graduation. The Houston Area Urban League will also work directly with Flatiron School to source diverse applicants, provide additional career training and job placement services to bootcamp graduates.  These are just a few of the ways we’re working with the Houston community to help small businesses and job seekers gain the skills they need to succeed. We’re excited to continue to listen and learn from local businesses this week.  Our teams are committed to helping small businesses and their communities across the United States and beyond. Please share your thoughts and stay up to date with the latest city announcements, news and program schedules at facebook.com/communityboost. For visuals from Facebook Community Boost Houston, see here for photos and here for videos.","data/Facebook newsroom/Facebook Community Boost Partners with Houston Organizations.txt"
"March 26, 2018  Facebook Community Boost Partners with St. Louis Organizations and Announces Next 8 Cities  By Dan Levy, VP Global SMB  In November we announced Facebook Community Boost, a program to help small businesses grow and equip people in their communities with digital skills. Our CEO Mark Zuckerberg first shared the announcement at a meeting with small business owners in St. Louis.   Today, less than 5 months later, we’re back in St. Louis to deliver on his promise of increasing our efforts to support small businesses. But in order to make a lasting impact, we know we can’t do this alone. Which is why we’re partnering with local organizations in every city we visit.  Scaling Digital Skills and Marketing Training for St. Louis   We’re working to understand the needs of individuals and communities, so that we can personalize our programs. In a recent survey, small businesses and job seekers in the St. Louis community told us that there is a gap between the digital skills they have compared to what they need to succeed:  84% of small business managers believe that digital advertising is an important skill for growing their business, but only 13% of managers rate themselves as excellent in this area. 93% of individuals looking for work in St. Louis say digital skills are important when looking for job, but only 12% rate themselves as excellent in this department. To help address these gaps, we’re partnering with the Savvy Coders and Urban League of Metropolitan St. Louis to deliver digital marketing and social media curriculum across the greater St. Louis area.  Scholarships and Workforce Development Through Coding Bootcamps  Additionally, our new Facebook Bootcamp pilot with Claim Academy will fund scholarships for their coding bootcamps, which have a greater than 90% job placement rate for graduates. As part of the program, local companies like Monsanto and Clearent will interview program graduates for entry-level developer positions in their organizations.  We’re also sponsoring the St. Louis launch of LaunchCode’s Discovery Program, a free curriculum for those without a technical background. The St. Louis Public Library will also integrate this free training into their learning programs.  These are just a few of the ways we’re working with the St. Louis community to help small businesses and job seekers gain the skills they need to succeed. We’re excited to continue to listen and learn from local businesses this week.  Upcoming Facebook Community Boost Events  Today, we’re also announcing the next eight US cities where Facebook Community Boost will be held. We’ll announce dates for these cities in the coming weeks.  Buffalo, New York Columbus, Ohio Hampton, Virginia Phoenix, Arizona Minneapolis, Minnesota Helena, Montana Denver, Colorado East Palo Alto/Menlo Park, California Our teams are committed to helping small businesses and their communities across the United States and beyond. Please share your thoughts and stay up to date with the latest city announcements, news and program schedules at facebook.com/communityboost.","data/Facebook newsroom/Facebook Community Boost Partners with St. Louis Organizations and Announces Next 8 Cities.txt"
"April 9, 2018  Facebook Launches New Initiative to Help Scholars Assess Social Media’s Impact on Elections By Elliot Schrage, Vice President of Communications and Public Policy, and David Ginsberg, Director of Research  Today, Facebook is announcing a new initiative to help provide independent, credible research about the role of social media in elections, as well as democracy more generally. It will be funded by the Laura and John Arnold Foundation, Democracy Fund, the William and Flora Hewlett Foundation, the John S. and James L. Knight Foundation, the Charles Koch Foundation, the Omidyar Network, and the Alfred P. Sloan Foundation.  At the heart of this initiative will be a group of scholars who will:  Define the research agenda; Solicit proposals for independent research on a range of different topics; and Manage a peer review process to select scholars who will receive funding for their research, as well as access to privacy-protected datasets from Facebook which they can analyze. Facebook will not have any right to review or approve their research findings prior to publication.  We’re excited about this initiative for two important reasons.  First, we think it’s an important new model for partnerships between industry and academia. Second, the last two years have taught us that the same Facebook tools that help politicians connect with their constituents — and different communities debate the issues they care about — can also be misused to manipulate and deceive.  We have made real progress since Brexit and the 2016 US presidential election in fighting fake news, as well as combating foreign interference, in elections in France, Germany, Alabama and Italy. But there is much more to do — and we don’t have all the answers. This initiative will enable Facebook to learn from the advice and analysis of outside experts so we can make better decisions — and faster progress.  In consultation with the foundations funding the initiative, Facebook will invite respected academic experts to form a commission which will then develop a research agenda about the impact of social media on society — starting with elections. The focus will be entirely forward looking. And our goals are to understand Facebook’s impact on upcoming elections — like Brazil, India, Mexico and the US midterms — and to inform our future product and policy decisions. The initial term of the commission will be one year and membership will be determined in the coming weeks. We are keen to have a broad range of experts — with different political outlooks, expertise and life experiences, gender, ethnicity and from a broad range of countries.  The commission will exercise its mandate in several ways:  Prioritization of research agenda. The research sponsored by this effort is designed to help people better understand social media’s impact on democracy — and Facebook to ensure that it has the right systems in place. For example, will our current product roadmap effectively fight the spread of misinformation and foreign interference? Specific topics may include misinformation; polarizing content; promoting freedom of expression and association; protecting domestic elections from foreign interference; and civic engagement. Commission members will learn about Facebook’s internal efforts related to elections, and source input from the academic community to determine the most important unanswered research questions. They will also begin to work with international experts to develop research evaluating Facebook’s impact in upcoming elections — with the goal of identifying and mitigating possible negative effects.  Solicitation of independent research. As the commission identifies areas to assess Facebook’s effectiveness, it will work with Facebook to develop requests for research proposals. In accordance with standard academic protocols, proposals will be subject to rigorous peer view. The peer review process will be managed by the Social Science Research Council, which is well placed to tap into the global network of substantive, ethical, and privacy experts. Based on input from the peer review process, the commission will independently select grantees who will receive funds from the supporting foundations, and, when appropriate, privacy-protected data from Facebook.  Providing access to information while protecting privacy. Once the commission identifies the most important questions, we are committed to helping grantees obtain the right data to answer them. Sometimes these datasets will come from Facebook, and sometimes they will come from other sources like surveys or focus groups.  Fundamental to this entire effort is ensuring that people’s information is secure and kept private. Facebook and our funding partners recognize the threat presented by the recent misuse of Facebook data, including by an academic associated with Cambridge Analytica. At the same time, we believe strongly that the public interest is best served when independent researchers have access to information. And we believe that we can achieve this goal while ensuring that privacy is preserved and information kept secure.  Any proposal submitted through this process must first have been reviewed by a university Institutional Review Board (IRB), or the international equivalent. And when Facebook data is requested, proposals will be subject to additional review by Facebook’s privacy and research review teams — as well as external privacy experts that the commission identifies. These reviews will help ensure that Facebook acts in accordance with its legal and ethical obligations to the people who use our service, as well as the academic and ethical integrity of the research process.  Facebook is building a dedicated team to work with the commission and academic researchers to develop the approved, privacy-protected datasets, which will be kept exclusively on Facebook’s global network of secure servers and subject to continuous audit. The commission will oversee publication, ensuring that only aggregated, anonymized results are reported. It will also develop a process to apply for data access for purposes of replication.  Independent and transparent reporting. Facebook and the foundations funding this project are committed to transparency around the rationale for the structure and membership of the commission. Once established, the commission will have the authority to regularly report on its activities and Facebook’s. This will include the decision-making criteria guiding both the research agenda and scholar selection. And the research coming from this initiative will be public, and Facebook will not approve it before it’s published.  Facebook plays an important role in elections around the world — helping people connect and discuss the important issues of the day. We were slow to spot foreign interference in the 2016 US presidential elections, as well as issues with fake accounts and fake news. Our teams have made good progress since then. By working with the academic community, we can help people better understand the broader impact of social media on democracy — as well as improve our work to protect the integrity of elections.  Gary King of Harvard University and Nate Persily of Stanford Law School have been instrumental in developing this innovative model for academic collaboration. You can read more about their model here.","data/Facebook newsroom/Facebook Launches New Initiative to Help Scholars Assess Social Media’s Impact on Elections.txt"
"March 25, 2018  Fact Check: Your Call and SMS History You may have seen some recent reports that Facebook has been logging people’s call and SMS (text) history without their permission.  This is not the case.  Opt-in Features in Facebook Lite and Messenger Call and text history logging is part of an opt-in feature for people using Messenger or Facebook Lite on Android. This helps you find and stay connected with the people you care about, and provides you with a better experience across Facebook. People have to expressly agree to use this feature. If, at any time, they no longer wish to use this feature they can turn it off in settings, or here for Facebook Lite users, and all previously shared call and text history shared via that app is deleted. While we receive certain permissions from Android, uploading this information has always been opt-in only.  We introduced this feature for Android users a couple of years ago. Contact importers are fairly common among social apps and services as a way to more easily find the people you want to connect with. This was first introduced in Messenger in 2015, and later offered as an option in Facebook Lite, a lightweight version of Facebook for Android.  How It Works When you sign up for Messenger or Facebook Lite on Android, or log into Messenger on an Android device, you are given the option to continuously upload your contacts as well as your call and text history. For Messenger, you can either turn it on, choose ‘learn more’ or ‘not now’. On Facebook Lite, the options are to turn it on or ‘skip’. If you chose to turn this feature on, we will begin to continuously log this information, which can be downloaded at any time using the Download Your Information tool.    If, at any point, you no longer wish to continuously upload this information, you can easily turn this feature off in your settings. You can also turn off continuous call and text history logging while keeping contact uploading enabled. You can also go to this page to see which contacts you have uploaded from Messenger, and you can delete all contact information you’ve uploaded from that app should you choose.  We never sell this data, and this feature does not collect the content of your text messages or calls When this feature is enabled, uploading your contacts also allows us to use information like when a call or text was made or received. This feature does not collect the content of your calls or text messages. Your information is securely stored and we do not sell this information to third parties. You are always in control of the information you share with Facebook.","data/Facebook newsroom/Fact Check Your Call and SMS History.txt"
"March 5, 2018  Global Safety Summit By Antigone Davis, Global Head of Safety  Every year Facebook convenes a group of leaders in safety and technology for our Global Safety Summit. This year we returned in Washington, DC and were joined by over 100 organizations from 35 countries.  It has never been more important to hear from the people who are at the front lines of keeping communities safe. The organizations represented have a vision about how to make the world a better place in their neighborhoods, towns and cities, both online and off. Their work often inspires the engineers who are building products at Facebook, and their stories enable us to understand how Facebook and our family of apps and services can help.  The event included discussion from experts on a wide range of topics— from issues of safety and technology to how tech is impacting our well-being, and how to keep the most vulnerable people safe when they go online. We also shared examples of how people on Facebook are building community and asked for feedback on how we can best build products for families.  Over the years we’ve learned that people watch out for each other on Facebook. It’s a place to share and connect with the people who matter to you. We’ve often developed products based on how people are already coming to Facebook for help.  Below are some highlights of what was covered.  Welcome   Joel Kaplan — VP, Global Policy, Facebook Antigone Davis — Director, Global Head of Safety, Facebook  Safety and Technology: Opportunities and Challenges Around the World  Panel featuring ideas to help keep people safe around the world.   Cindy Southworth — National Network to End Domestic Violence Hema Budaraju — Facebook James Hairston — Oculus Alex Holmes — Diana Award Will Gardner — Childnet Moderator: Karen Attiah — Global Opinions Editor, Washington Post  Fireside Chat – Connect in Meaningful Ways Online Discussion about how the research team at Facebook works with our product teams to incorporate well-being principles, and review some of the top scientific research on well-being and social media.   David Ginsberg — Director of Research, Facebook Moderator: Donna Leinwand-Leger — Managing Editor, USA Today  Building Better Products for Families  Presentation on how Facebook is working with parents and experts as it thinks about products for youth and how that work informed and influenced how we built Messenger Kids.  Gathering Insights from Families   Antigone Davis — Director, Global Head of Safety, Facebook Dr. Sean Arthurs — National PTA  Messenger Kids: Building Better Products for Families   Tarunya Govindarajan — Product Manager, Messenger Kids  Teens and Technology: Changing the World  Panel featuring young leaders using technology to further their mission. This group will talk about a wide variety of topics, from how social media helps their work and how they manage the risks of technology, to resiliency, digital literacy, and youth rights.   Harnidh Kaur — Published Feminist Poet Camryn Garett — Writer Evelyn Atieno — Founder of @TheAffinityMag Amika George — Founder of #FreePeriods Tábata C. Amaral de Pontes — Founder of Mapa educação Moderator: Taylor Trudon — Brand Marketing Manager, Reader Engagement— New York Times  Next Gen Safety Tech Hear from a panel of online safety organizations and experts who are exploring cutting edge technology in the fight against child exploitation, trafficking, sextortion, the non-consensual sharing of intimate images and other abuses.   Fred Langford — Internet Watch Foundation Julie Cordua — Thorn Lindsey Olson — National Center for Missing and Exploited Children Danielle Citron — Cyber Civil Rights Initiative Rachael Tucker — Counselor to the Attorney General at the U.S. Department of Justice  Keeping People Safe on Facebook: A Fireside Chat Discussion about how Facebook approaches online safety, including the opportunities and challenges.   Guy Rosen — VP, Product Management, Facebook Antigone Davis — Director, Global Head of Safety, Facebook Moderator: Kim Hart — Axios  A Conversation: Young People, Technology and Well Being  This panel of child-development experts will share their perspectives on the most top-of-mind issue.   Dr. Megan Moreno — Director of Social Media Adolescent Health Research Team, University of Wisconsin Dr. Kevin Clark — Director for Center for Digital Media and Diversity, George Mason University Dr. Pam Hurst-Della Pietra — Founder and President, Children and Screens: Institute of Digital Media and Child Development Dr. Anja Dinhopl — Researcher, Facebook David Kleeman — SVP, Global Trends, Dubit Moderator: Dr. Michael Rich — Associate Professor of Pediatrics at Harvard Medical School, Associate Professor of Social and Behavioral Sciences at the Harvard School of Public Health","data/Facebook newsroom/Global Safety Summit.txt"
"March 1, 2018  Hard Questions: Live from Facebook’s Global Safety Summit  Today Hard Questions continues its series of interviews with the digital news site Axios, with a discussion between two of Facebook’s senior executives — Global Head of Safety Antigone Davis and Vice President of Product Management Guy Rosen. Axios managing editor Kim Hart will be the moderator. The subject is how we’re working to keep Facebook services safe from predators and other bad actors, including the complex challenges we face when it comes to online safety.  The discussion is part of the annual Facebook Global Safety Network Summit, which convenes leaders in the fields of safety and technology. This year there are over 100 organizations from 35 countries attending the summit at the Newseum in Washington, DC. Watch the discussion on Facebook Live.   Read more about our Hard Questions series. We want your input on what other topics we should address — and what we could be doing better. Please send suggestions to hardquestions@fb.com.","data/Facebook newsroom/Hard Questions Live from Facebook’s Global Safety Summit.txt"
"March 21, 2018  Hard Questions: Update on Cambridge Analytica  Today, Mark Zuckerberg announced measures Facebook is taking to better protect people’s data, given reports that Cambridge Analytica may still be in possession of Facebook user data that was improperly obtained. We shared more information on the steps we’re taking to prevent abuse of our platform in a post on our Newsroom.    Mark spoke with reporters today. You can read his Q&A with WIRED here, The New York Times here, and Recode here. He also sat down for an interview with CNN to answer more questions.   Read more about our Hard Questions series. We want your input on what else we should address — and what we could be doing better. Please send suggestions to hardquestions@fb.com.","data/Facebook newsroom/Hard Questions Update on Cambridge Analytica.txt"
"March 29, 2018  Hard Questions: What is Facebook Doing to Protect Election Security?  Hard Questions is a series from Facebook that addresses the impact of our products on society.  Last fall Mark Zuckerberg announced the steps we’re taking to protect elections from abuse and exploitation. Given all the work underway, we want to provide regular updates on what we’re doing and the progress we’re making. Today, leaders from Facebook spoke with members of the press to review our ongoing election efforts. The following is a transcript of their remarks.  Guy Rosen, VP of Product Management  Morning everyone, I’m Guy Rosen, and I help coordinate all of the safety and security work underway here at Facebook.  By now, everyone knows the story: during the 2016 US election, foreign actors tried to undermine the integrity of the electoral process. Their attack included taking advantage of open online platforms — such as Facebook — to divide Americans, and to spread fear, uncertainty and doubt.  Now, none of us can turn back the clock, but we are all responsible for making sure the same kind of attack our democracy does not happen again. And we are taking our role in that effort very, very seriously.  Today, we’re going to outline how we’re thinking about elections, and give you an update on a number of initiatives designed to protect and promote civic engagement on Facebook.  There are four main election security areas that we are working on. They are:  First, combating foreign interference, Second, removing fake accounts, Third, increasing ads transparency, and Fourth, reducing the spread of false news. This is a comprehensive approach we deploy in elections around the world, and we’re here today to share our thinking about what we are doing so that you can better understand our approach.  Now, I’ll turn it over to Alex.  Alex Stamos, Chief Security Officer  Thanks, Guy. Good morning everyone, I’m Alex Stamos, Facebook’s Chief Security Officer, and I would like to discuss how we think about different types of misinformation — and the adversaries who propagate it.  When you tease apart the overall digital misinformation problem, you find multiple types of bad content and many bad actors with different motivations. It is important to match the right approach to these various challenges. And that requires not just careful analysis of what has happened. We also have to have the most up to date intelligence to understand completely new types of misinformation.  The term “fake news” is used to describe a lot of different types of activity that we would like to prevent. When we study these issues, we have to first define what is actually “fake.” The most common issues are:  Fake identities– this is when an actor conceals their identity or takes on the identity of another group or individual; Fake audiences– so this is using tricks to artificially expand the audience or the perception of support for a particular message; False facts – the assertion of false information; and False narratives– which are intentionally divisive headlines and language that exploit disagreements and sow conflict. This is the most difficult area for us, as different news outlets and consumers can have completely different opinions on what an appropriate narrative is even if they agree on the facts. Once we have an understanding of the various kinds of “fake” we need to deal with, we then need to distinguish between motivations for spreading misinformation. Because our ability to combat different actors is based upon preventing their ability to reach these goals.  The most common motivation for organized, professional groups is money. The majority of misinformation we have found, by both quantity and reach, has been created by groups who gain financially by driving traffic to sites they own. When we’re fighting financially motivated actors, our goal is to increase the cost of their operations while driving down their profitability. This is not wholly unlike how we have countered various types of spammers in the past.  The second class of organized actors are the ones who are looking to artificially influence public debate. These cover the spectrum from private but ideologically motivated groups to full-time employees of state intelligence services. Their targets might be foreign or domestic, and while much of the public discussion has been about countries trying to influence the debate abroad, we also must be on guard for domestic manipulation using some of the same techniques.  Misinformation can also be spread by less organized groups or individuals. These might be people who enjoy causing chaos and disruption, who you might call a classic internet “troll.” Or they might be innocent users who share a false story without realizing that the story or the person pushing it are fake.  Some groups might have multiple motivations — for example, some ideologically driven groups are also self-funded via the ad money they generate from their sites.  Each country we operate in and election we are working to support will have a different range of actors with techniques are customized for that specific audience. We are looking ahead by studying each upcoming election and working with external experts to understand the actors involved and the specific risks in each country. We are then using this process to guide how we build and train teams with the appropriate local language and cultural skills.    At the end of the day, we’re trying to develop a systematic and comprehensive approach to tackle these challenges, and then to map that approach to the needs of each country or election.  Let me turn it now to Samidh to outline some of our specific product efforts.  Samidh Chakrabarti, Product Manager  Thanks, Alex. I’m Samidh Chakrabarti, I’m a product manager here at Facebook and I lead all of our product work related to elections security and civic engagement.  Let me start with our ongoing efforts to fight fake accounts — because that’s one of the most frequent ways that we see bad actors try to hide behind false identities. Over the past year, we’ve gotten increasingly better at finding and disabling fake accounts. We’re now at the point that we block millions of fake accounts each day at the point of creation before they can do any harm. We’ve been able to do this thanks to advances in machine learning, which have allowed us to find suspicious behaviors — without assessing the content itself.  Now our work also includes a new investigative tool that we can deploy in the lead-up to elections. I’d love to tell you a little bit about how it works.  Rather than wait for reports from our community, we now proactively look for potentially harmful types of election-related activity, such as Pages of foreign origin that are distributing inauthentic civic content. If we find any, we then send these suspicious accounts to be manually reviewed by our security team to see if they violate our Community Standards or our Terms of Service.  And if they do, we can quickly remove them from Facebook. This proactive approach has allowed us to move more quickly and has become an important way for us to prevent misleading or divisive memes from going viral.  Now as Mark briefly mentioned last week, we first piloted this tool last year around the time of the Alabama special Senate race. By looking specifically for foreign interference, we were able to identify a previously unknown set Macedonian political spammers that appeared to be financially motivated. We then quickly blocked them from our platform.  We’ve since used this in many places around the world, such as in the Italian election, and we’ll deploy it moving forward for elections around the globe, including the US midterms.  Let me close by saying that to support these and other security initiatives, we are making huge investments both in technology and in talent. This year, for example, we are doubling the number of people who work on safety issues overall from 10,000 to 20,000, and that includes content reviewers, systems engineers and security experts. So far, I’m pleased to say we’re on track, and our defenses are steadily coming together for the US midterms.  Now let me now turn to my colleague Tessa.  Tessa Lyons, Product Manager  Thanks, Samidh. I’m Tessa Lyons. I’m a Product Manager on News Feed and I focus on false news.  We know that people want to see accurate information on Facebook – and so do we. So we’re working hard to stop the spread of false news.  Today, I want to talk about one part of our strategy: our partnership with third-party fact-checking organizations. We’re seeing progress in our ability to limit the spread of articles rated false by fact-checkers, and we’re scaling our efforts.  Here’s how it works:  We use signals, including feedback from people on Facebook, to predict potentially false stories for fact-checkers to review. When fact-checkers rate a story as false, we significantly reduce its distribution in News Feed — dropping future views on average by more than 80%. We notify people who’ve shared the story in the past and warn people who try to share it going forward. For those who still come across the story in their News Feed, we show more information from fact-checkers in a Related Articles unit. We use the information from fact-checkers to train our machine learning model, so that we can catch more potentially false news stories and do so faster. We know that we will always be behind if we’re just going after individual stories — so we also take action against Pages and domains that repeatedly share false news. We reduce their distribution and remove their ability to advertise and monetize – stopping them from reaching, growing, or profiting from their audience.    We’re ramping up our fact-checking efforts to fight false news around elections. We’re scaling in the US and internationally, expanding beyond links to photos and videos, and increasing transparency.  In the US, we recently announced a partnership with The Associated Press to use their reporters in all 50 states to identify and debunk false and misleading stories related to the federal, state and local US midterm elections. Internationally, we have fact-checking partners in six countries and we’re working to expand to more. Our most recent launches were in Italy and Mexico, where we enabled fact-checking partners to proactively identify and rate stories, ensuring we could take action quickly in the run-up to their elections. As of yesterday, we’re fact-checking photos and videos, in addition to links. We’re starting in France with the AFP and will be scaling to more countries and partners soon. And, over the coming months, we’ll be taking additional steps to increase transparency around our fact-checking efforts, including clearer notifications to Page admins and greater clarity around the appeals process. Finally, we know we can’t go it alone. So we’re doubling down on our partnerships with academics, technology companies and other partners.  Now, let me turn it over to Rob Leathern, to talk about ads transparency.  Rob Leathern, Product Management Director  Thanks, I’m Rob Leathern and I’m on the ads team. We believe people should be able to easily understand why they’re seeing ads, who paid for them, and what other ads that advertiser is running. Last fall we announced we will build a new transparency feature for all ads on Facebook and provide additional transparency for US federal election-related ads.  Already we’ve been testing transparency across all ads in Canada, something we call View Ads. With it, you can click on any Facebook Page, and select About, and scroll to View Ads. There you’ll see all ads that Page is running across Facebook — not just the ones meant for you. This summer we’ll make that feature globally available.  Next we’ll build on our ads review process and begin authorizing US advertisers placing political ads. This spring, in the run up to the US midterm elections, advertisers will have to verify and confirm who they are and where they are located in the US. The process will include a number of checks and steps:  First, Page admins will have to submit their government-issued IDs and provide a physical mailing address for verification, Second, we’ll confirm each address by mailing a letter with a unique access code that only their specific Facebook account can use, and, Third, advertisers will also have to disclose what candidate, organization or business they represent. Once authorized, an advertiser’s election-related ads will be clearly marked in people’s Facebook and Instagram feeds. This is similar to the disclosure you see today for political ads on TV. The political label will also list the person, company, or organization that paid for the ad with a “paid for by” disclosure.  This summer, we’ll launch a public archive showing all ads that ran with a political label. Beyond the ad creative itself, we’ll also show how much money was spent on each ad, the number of impressions it received, and the demographic information about the audience reached. And we will display those ads for four years after they ran. So researchers, journalists, watchdog organizations, or individuals who are just curious will be able to see all of these ads in one place. This will offer an unmatched view of paid political messages on the platform.  We recognize this is a place to start and will work with outside experts to make it better. We also look forward to bringing unprecedented advertising transparency to other countries and other political races.  Now I’ll turn it back to Guy to wrap up.  Guy Rosen, VP of Product Management  Thanks. Let me close with a last — but very important — point about why we’re even doing this work: because civic discourse is something we at Facebook strongly believe in. And we know it can thrive on our platform when it’s safe, it’s authentic and it’s accurate. That’s our goal and that’s why we are taking all of the steps we just outlined.","data/Facebook newsroom/Hard Questions What is Facebook Doing to Protect Election Security.txt"
"April 4, 2018  Hard Questions: Q&A with Mark Zuckerberg on Protecting People’s Information  Hard Questions is a series from Facebook that addresses the impact of our products on society.  Today, Mark Zuckerberg spoke with members of the press about Facebook’s efforts to better protect people’s information. The following is a transcript of his remarks and the Q&A that followed.  Opening Remarks Hey everyone. Thanks for joining today. Before we get started today, I just want to take a moment to talk about what happened at YouTube yesterday.  Silicon Valley is a tight-knit community, and we all have a lot of friends over there at Google and YouTube.  We’re thinking of everyone there and everyone who was affected by the shooting.  Now I know we face a lot of important questions. So I just want to take a few minutes to talk about that upfront, and then we’ll take about 45 minutes of your questions.  Two of the most basic questions that I think people are asking about Facebook are: first, can we get our systems under control and can we keep people safe, and second, can we make sure that our systems aren’t used to undermine democracy?  And I’ll talk about both of those for a moment and the actions that we’re taking to make sure the answers are yes. But I want to back up for a moment first.  We’re an idealistic and optimistic company. For the first decade, we really focused on all the good that connecting people brings. And as we rolled Facebook out across the world, people everywhere got a powerful new tool for staying connected, for sharing their opinions, for building businesses. Families have been reconnected, people have gotten married because of these tools. Social movements and marches have been organized, including just in the last couple of weeks. And tens of millions of small business now have better tools to grow that previously only big companies would have had access to.  But it’s clear now that we didn’t do enough. We didn’t focus enough on preventing abuse and thinking through how people could use these tools to do harm as well. That goes for fake news, foreign interference in elections, hate speech, in addition to developers and data privacy. We didn’t take a broad enough view of what our responsibility is, and that was a huge mistake. It was my mistake.  So now we have to go through every part of our relationship with people and make sure that we’re taking a broad enough view of our responsibility. It’s not enough to just connect people, we have to make sure that those connections are positive and that they’re bringing people closer together. It’s not enough to just give people a voice, we have to make sure that people are not using that voice to hurt people or spread disinformation. And it’s not enough to give people tools to sign into apps, we have to ensure that all of those developers protect people’s information too. It’s not enough to have rules requiring they protect information, it’s not enough to believe them when they tell us they’re protecting information — we actually have to ensure that everyone in our ecosystem protects people’s information.  So across every part of our relationship with people, we’re broadening our view of our responsibility, from just giving people tools to recognizing that it’s on us to make sure those tools are used well.  Now let me get into more specifics for a moment.  With respect to getting our systems under control, a couple of weeks ago I announced that we were going to do a full investigation of every app that had a large amount of people’s data before we locked down the platform, and that we’d make further changes to restrict the data access that developers could get.  [VP, Product Partnerships] Ime Archibong and [Chief Technology Officer] Mike Schroepfer followed up with a number of changes we’re making, including requiring apps you haven’t used in a while to get your authorization again before querying for more of your data. And today we’re following up further and restricting more APIs like Groups and Events. The basic idea here is that you should be able to sign into apps and share your public information easily, but anything that might also share other people’s information — like other posts in groups you’re in or other people going to events that you’re going to — those should be more restricted. I’m going to be happy to take questions about everything we’re doing there in a minute.  I also want to take a moment to talk about elections specifically.  Yesterday we took a big action by taking down Russian IRA pages targeting their home country.  Since we became aware of this activity, their activity after the 2016 US elections, we’ve been working to root out the IRA and protect the integrity of elections around the world. And since then there have been a number of important elections that we’ve focused on. A few months after the 2016 elections there was the French presidential election, and leading up to that we deployed some new AI tools that took down more than 30,000 fake accounts. After that there was the German election, where we developed a new playbook for working with the local election commission to share information on the threats we were each seeing. And in the US Senate Alabama special election last year, we successfully deployed some new AI tools that removed Macedonian trolls who were trying to spread misinformation during the election.  So all in, we now have about 15,000 people working on security and content review, and we’ll have more than 20,000 by the end of this year.  This is going to be a big year of elections ahead, with the US midterms and presidential elections in India, Brazil, Mexico, Pakistan, Hungary and others — so this is going to be a major focus for us.  But while we’ve been doing this, we’ve also been tracing back and identifying this network of fake accounts the IRA has been using so we can work to remove them from Facebook entirely. This was the first action we’ve taken against the IRA in Russia itself, and it included identifying and taking down Russian news organization that we determined were controlled and operated by the IRA. So we have more work to do here, and we’re going to continue working very hard to defend against them.  All right. So that’s my update for now. We expect to make more changes over the coming months, and we’ll keep you updated, and now let’s take some questions.  Q&A David McCabe, Axios: Given that Colin testified just last year, and more has come out since then, and given that the numbers around the time of the IRA operation changed so drastically, why should lawmakers—why should users and Congress trust that you are giving them a full and accurate picture now?  Mark: Of the IRA — I think there is going to be more content that we are going to find over time. As long as there are people employed in Russia who have the job of trying to find ways to exploit these systems, this is going to be a never-ending battle. You never fully solve security — it’s an arms race. In retrospect we were behind, and we didn’t invest enough in it up front. We had thousands of people working on security, but nowhere near the 20,000 that we’re going to have by the end of this year. So I am confident we are making progress against these adversaries. But they were very sophisticated, and it would be a mistake to assume that you can ever fully solve a problem like this, or think that they are going to give up and stop doing what they are doing.Rory Cellan Jones, BBC: You, back in November 2016 when you could say this crisis began, dismissed as crazy the idea that fake news could influence the election, and more recently here in the UK you’ve turned down an invitation to speak to our Parliamentarians in the House of Commons, just as we learn tonight that 1 million UK users were affected by the Cambridge Analytica data leak. Are you taking this seriously enough, and can you convince British users that you care enough about the situation?  Mark: Yes. So we announced today that I’m going to be testifying in front of Congress. I imagine that is going to cover a lot of ground. I am going to be sending one of our top folks. I believe it’s going to be [Mike Schroepfer], the CTO, or Chris Cox, the product officer. These are the top folks who I run the company with—to answer additional questions from countries and other places.  Oh sorry, I should also probably address — you asked about my comments after the 2016 election. I’ve said this already —but I think at this point that I clearly made a mistake by just dismissing fake news as “crazy”— as having an impact. People will analyze the actual impact of this for a long time to come, but what I think was clear at this point is that it was too flippant. I should have never referred to it as crazy. This is clearly a problem that requires careful work, and since then we’ve done a lot to fight the spread of disinformation on Facebook from working with fact checkers to making it so that we’re trying to promote and work with broadly trusted news sources. But this is an important area of work for us.  Ian Sherr, CNET: So you just announced 87 million people affected by the Cambridge Analytica stuff today. How long did you know this number was affected? Because the 50 million number was out there for quite a while. I know you guys weren’t specifically saying that, but it feels like the data keeps changing on us. And we’re not getting a full forthright view of what’s going on here.  Mark: We only just finalized our understanding of the situation in the last I think couple of days on this. And as you said, we didn’t put out the 50 million number. That came from other parties. We wanted to wait until we had the full understanding. Just to give you the complete picture on this: we don’t have logs going back from when exactly [Aleksandr] Kogan’s app queried for everyone’s friends. What we did was basically constructed the maximum possible number of friends lists that everyone could have had over the time, and assumed that Kogan queried each person at the time when they had the maximum number of connections that would’ve been available to them. That’s where we came up with this 87 million number. We wanted to take a broad view that is a conservative estimate. I am quite confident that given our analysis that it is not more than 87 million. It very well could be less, but we wanted to put out the maximum we felt that it could be as that analysis says.  David Ingram, Reuters: Hi Mark. I’m wondering if you can you address the audits that you’re doing for third-party app developers. Specifically, I hear what you’re saying about taking a broader view now about the company’s responsibility, but why weren’t there audits of the use of social graph API done years ago back in the 2010-2015 period?  Mark: Well, in retrospect, I think we clearly should have been doing more all along. But just to speak to how we were thinking about it at the time, as just a matter of explanation, I’m not trying to defend this now: I think our view in a number of aspects of our relationship with people is that our job is to give them tools, and that it was largely people’s responsibility how they chose to use them — whether that’s tools on how to share your voice, tools on how to log in to apps and bring your information to them. I think it was wrong in retrospect to have that limited of a view, but the reason why we acted the way that we did was because we viewed that when someone chose to share data with the platform it acted the way it was designed. With this personality quiz app, our view is that yes, Kogan broke the policies and that he broke peoples’ expectations. But also that people chose to share that data with him. I think today, given what we know, not just about developers, but across all of our tools, and across what our place in society is, it’s such a big service that’s so central in peoples’ lives. I think we need to take a broader view of our responsibility. We’re not just building tools, but we need to take full responsibility for the outcome and how people use those tools as well. That’s at least why we didn’t do it at the time, but knowing what I know today, clearly we should have done more. And we will going forward.  Cecilia Kang, New York Times: Hi. Thanks for taking my question. Mark, you have indicated that you could be comfortable with some sort of regulation, and I think you alluded to potentially political ads. I’d like to ask you about privacy regulations that are about to take form, or take effect in Europe–GDPR. Would you be comfortable with those types of data protection regulations in the United States and deeper for global users?  Mark: Overall, I think regulations like the GDPR are very positive. I was somewhat surprised by yesterday’s Reuters story that ran on this because the reporter asked if we are planning on running the controls for GDPR across the world and my answer was yes. We intend to make all the same controls and settings available everywhere, not just in Europe. Is it going to be exactly the same format? Probably not. We need to figure out what makes sense in different markets with the different laws and different places. But—let me repeat this—we’ll make all controls and settings the same everywhere, not just in Europe.  Tony Romm, Washington Post: In a blog post, you acknowledged that profile information had been scraped by malicious actors? Who are these actors? Are they political organizations like Cambridge or others? And given that, do you believe this was all in violation of your 2011 settlement with the FTC? Thanks.  Mark: To take a step back on this, all of the changes we announced today were about ways that we built tools that were useful to a lot of people on sharing information or connecting with people but that we basically felt like the amount of information that potential bad actors could get—or specific folks who we’ve observed—could potentially misuse this. Whether that’s the changes are in groups or events, it’s not unreasonable to have an API where someone can bring the activity in a group to an app and be able to interactive with that in a group in an external app. We still wanted to shut that down because we felt like there was too many apps and too many folks who would have had access to people’s content, and that would have been problematic. It’s a similar situation with search. What we found here is we built this feature, and its very useful. There a lot of people who were using it until we shut it down today to look up the people who they want to add as friends but they don’t have as friends yet. Especially in places where there are languages that makes it easier to type in a phone number or a number than for someone’s name, or where a lot of people have the same name, it’s helpful to have a unique identifier to disambiguate. But I think what was also clear is that the methods of rate limiting this weren’t able to prevent malicious actors who cycled through hundreds of thousands of different IP address and did a relatively small number of queries for each one. Given that and what we know today, it just makes sense to shut that down.  You asked about the FTC consent order. We’ve worked hard to make sure that we comply with it. I think the reality here is that we need to take a broader view of our responsibility, rather than just the legal responsibility. We’re focused on doing the right thing and making sure people’s information is protected, and we’re doing investigations. We’re locking down the platform, et cetera. I think that our responsibilities to the people that use Facebook are greater than just what’s written in that order, and that’s the standard I want to hold us to.  Hannah Kuchler, Financial Times: Hi Mark. Thanks for taking my question. Investors have raised a lot of concerns about whether this is the result of corporate governance issues at Facebook. Has the board discussed whether you should step down as chairman?  Mark: Not that I’m aware of.  Alexis Madrigal, The Atlantic: Every company, big and small, balances the service they provide with the needs of the business. In light of [Andrew Bosworth] Boz’s post and your rethinking of Facebook’s responsibility, have you ever made a decision that benefited Facebook’s business but hurt the community?  Mark: I’ll answer your question, but first because you brought up Boz’s post. Let me take a moment to make sure that everyone understands that I disagreed with that at the time and I disagree with that now. I don’t think that it stands for what most people inside the company believe. If you looked at the comments on that thread, when he initially wrote it, it was massively negative. So, I feel like that’s an important point to set aside.  In terms of the questions you asked, balancing stakeholders, the thing that I think makes our product challenging to manage and operate are not the trade-offs between the people and the business — I actually think that those are quite easy because over the long term the business will be better if you serve people. I just think that it would be near-sighted to focus on short-term revenue over what value to people is, and I don’t think we are that short-sighted. All of the hard decisions that we have to make are actually trade-offs between people. One of the big differences between the type of product that we are building is — which is why I refer to it as a community and what I think some of the specific governance challenges we have are — the different people that use Facebook have different interests. Some people want to share political speech that they think is valid, and other people feel like it’s hate speech. And then, people ask us, “Are you just leaving that up because you want people to be able to share more?” These are real values and questions and trade-offs. Free expression on the one hand, making sure it’s a safe community on the other hand. We have to make sure we get to the right place, and we’re doing that in an environment that’s not static. The social norms are changing continually, and they’re different in every country around the world. Getting those trade-offs right is hard, and we certainly don’t always get them right. To me, that’s the hard part about running the company—not the trade-off between the people and the business.  Alyssa Newcomb, NBC News: Hi Mark, you said you’ve clearly made some mistakes in past, and I’m wondering do you still feel like you’re the best person to run Facebook moving forward?  Mark: Yes. I think life is about learning from the mistakes and figuring out what you need to do to move forward. A lot of times people ask, “What are the mistakes you made early on, starting the company, or what would you try to do differently?” The reality of a lot of this is that when you are building something like Facebook that is unprecedented in the world, there are going to be things that you mess up. And if we had gotten this right, we would have messed something else up. I don’t think anyone is going to be perfect, but I think what people should hold us accountable for is learning from the mistakes and continually doing better and continuing to evolve what our view of our responsibility is — and, at the end of the day, whether we’re building things that people like and that make their lives better. I think it’s important to not lose sight of that through all of this. I’m the first to admit that we didn’t take a broad enough view of what our responsibilities were. But, I also think it’s important to keep in mind that there are billions of people who love the services that we’re building because they’re getting real value and being able to connect and build connections and relationships on day-to-day basis. And that’s something I’m really proud of our company for doing, and I know that we will keep on doing that.  Josh Constine, TechCrunch: Thank you. During today’s disclosure and announcement, Facebook explained that the account recovery and search tools using email and phone number could have been used to scrape information about of all of Facebook’s users. When did Facebook find out about this scraping operation, and, if that was before a month ago, why didn’t Facebook inform the public about it immediately?  Mark: We looked into this and understood it more over the last few days as part of the audit of our overall system. Everyone has a setting on Facebook, that controls — it’s right in your privacy settings — whether people can look you up by your contact information. Most people have that turned on, and that’s the default, but a lot of people have also turned it off. So it’s not quite everyone, but certainly the potential here would be that over the period of time that this feature has been around, people have been able to scrape public information. The information—that if you have someone’s phone number, you can put that in, and get a link to their profile which pulls their public information. So, I certainly think that it is reasonable to expect that if you had that setting turned on, that at some point during the last several years, someone has probably accessed your public information in this way.  Will Oremus, Slate: Thanks very much for doing this. You run a company that relies on people being willing to share data, that is then used to target them with ads. We also now know that it can be used in more manipulative ways or ways they don’t expect. We also know you’re protective of your own privacy. You acknowledged that you put tape over your webcam at one point, think you bought one of the lots surrounding your home just to get more privacy. I’m curious — what other steps do you take personally to protect your privacy online? Do you use an ad blocker? As a Facebook user, would you sign up for an apps like the personality quiz that folks signed up for? Thanks very much for having us.  Mark: I certainly use a lot of apps. I don’t know if I use that one specifically, but I am a power user of the internet here. In order to protect privacy, I would just advise that people follow best practices around security: turn on two-factor authentication, change passwords regularly, don’t have your password recovery responses be information that you made publicly available somewhere. All the basic practices, and then just look out and understand that most attacks are going to be social engineering, and not necessarily people trying to break into security systems. For Facebook specifically, one of the things we need to do and that I hope that more people look at are just the privacy controls that you have. I think, especially leading up to the GDPR event, a lot of people are asking us, “Okay, are you going to implement all those things?” And my answer is that we’ve had almost all of what’s in there implemented for years, around the world, not just in Europe. So, to me, the fact that a lot of people might not be aware of that is an issue, and I think we could do a better job of putting these tools in front of people and not just offering them, and I would encourage people to use them and make sure that they’re comfortable with how their information is used on our services and others.  Sarah Frier, Bloomberg: Hi Mark. There’s broad concern that these audits for developers won’t actually work, that the data that users gave to third-parties years ago could be anywhere by now. What results do you hope to achieve from the audit and what won’t you be able to find?  Mark: It’s a good question. No measure that you take on security is going to be perfect, but a lot of the strategy has to involve changing the economics of potential bad actors to make it not worth doing what they might do otherwise. So I think you’re right that we’re not going to be able to go out and necessarily find every single bad use of data. What we can do is make it a lot harder for folks to do that going forward: change the calculus on anyone who is considering doing something sketchy going forward. And I actually do think that we’ll be able to uncover a large amount of bad activity, of what exists, and we will be able to go in and do audits and ensure people go get rid of bad data.  Steve Kovach, Business Insider: Hi. Has anyone been fired related to the Cambridge Analytica issue or any other data privacy issue?  Mark: I have not… due to the Cambridge Analytica situation. We are still working through this. At the end of the day, this is my responsibility. So there have been a bunch of questions about that. I started this place. I run it. And I am responsible for what happens here. To the question before, I still think that I’m going to do the best job to help run it going forward. I’m not looking to throw anyone else under the bus for mistakes that we’ve made here.  Nancy Cortez, CBS News: Hi there. Thank you so much for taking the question. Your critics say, look, Facebook’s model, Facebook’s business model, depends on harvesting personal data. How can you ever personally reassure users that their data won’t be used in ways they don’t expect?  Mark: I think we can certainly do better job of explaining what we actually do. There are many misconceptions around what we do that I think we haven’t succeeded in clearing up for years. So, first, the vast majority of data that Facebook knows about you is because you chose to share it. Right? It’s not tracking. There are other internet companies or data brokers or folks that might try to track and sell data, but we don’t buy and sell. In terms of the ad activity, I means that’s a relatively smaller part of what we’re doing. The majority of the activity is people actually sharing information on Facebook, which is why people understand how much content is there, because people put all the photos and information there themselves. The second point, which I touched on briefly there: for some reason we haven’t been able to kick this notion for years that people think we will sell data to advertisers. We don’t. That’s not been a thing that we do. Actually it just goes counter to our own incentives. Even if we wanted to do that, it just wouldn’t make sense to do that. So, I think we can certainly do a better job of explaining this and making it understandable, but the reality is the way we run the service is: people share information, we use that to help people connect and to make the services better, and we run ads to make it a free service that everyone in world can afford.  Mathew Braga, CBC News: Hey Mark, I just want to go back to something that was brought up earlier around the scraping of profile information. I know Mike Schroepfer in his post said something about the scale and sophistication of the activity. And I’m just wondering can you put a little more context on that? Like what sort of scale are we talking about? Do you have exact numbers? Can you give us any harder sense than, sort of, what’s in that post?  Mark: In terms of sophistication, this is stuff that I’ve already said on some of the other answers, so I’ll try to keep this short. We had basic protections in place to prevent rate-limiting, making sure that accounts couldn’t do a whole lot of searches. But we did see a number of folks who cycled through many thousands of IPs, hundreds of thousands of IP addresses to abade the rate-limiting system, and that wasn’t a problem we really had a solution to. So now, that’s partially why the answer we came to is to shut this down even though a lot of people are getting a lot of use out of it. That’s not something we necessarily want to have going on. In terms of the scale, I think the thing people should assume, given this is a feature that’s been available for a while and a lot of people use it in the right way, but we’ve also seen some scraping, I would assume if you had that setting turned on, that someone at some point has accessed your public information in this way.  Rebecca Jarvis, ABC News: Hi Mark. Thanks for doing this. Cambridge Analytica has tweeted now since this conversation began, “When Facebook contacted us to let us know the data had been improperly obtained, we immediately deleted the raw data from our file server, and began the process of searching for and removing any of its derivatives in our system.” And I want to understand from you, now that you have this finalized understanding, do you agree with Cambridge’s interpretation and the tweet they just shared? And will you be pursuing legal action against Cambridge Analytica?  Mark: I don’t know that what we announced today really is connected to what they just said at all. What we announced with the 87 million is the maximum number of people we could calculate could have been accessed. We don’t actually know how many people’s information Kogan actually got. We don’t know what he sold to Cambridge Analytica, and we don’t know today what they have in their system. What we have said and what they’ve agreed to do, is a full forensic audit of their system, so we can get those answers. But, at the same time the UK government, and the ICO, are doing a government investigation and that takes precedence. So, we’ve stood down temporarily, to let the ICO do their investigation and their audit, and once that’s done, we’ll resume ours, so we can get answers to the questions that you’re asking and ultimately to make sure that none of the data persists or is being used improperly. And at that point if it makes sense, we will take legal action if we need to do that to protect people’s information.  Alex Kantrowitz, BuzzFeed: Hey Mark, thanks so much for doing this. We should do this every month, this is great. So, my question is that Facebook is really good at making money. But I wonder if your problems could be somewhat mitigated if the company didn’t try to make so much. So, you can still run Facebook as a free service and collect significantly less data and offer significantly less ad targeting criteria. So, I wonder if you think that would put you and society at less risk and if you think it’s something you’d consider doing?  Mark: People tell us that if they’re going to see ads, they want the ads to be good. And the way to make the ads good, is by making it so that when someone tells us they have an interest, they like technology or they like skiing or whatever it is they like, that the ads are actually tailored to what they care about. So, like most of the hard decisions that we make, this is one where there is a trade-off between values that people really care about. On the one hand people want relevant experiences, and on the other hand I do think that there is some discomfort for how data is used in systems like ads. But I think the feedback is overwhelming on the side of wanting a better experience. You know, maybe its 95-5 or something like that in terms of the preferences that people state to us and in their use of the product. So, that informs us of decisions that we make here to offer the best service to people, but these are hard values trade-offs and I think we are doing the right thing to serve people better.  Nancy Scola, POLITICO: When you became aware in 2015 that Cambridge Analytica inappropriately accessed this Facebook data, did you know that firm’s role in American politics and in Republican politics in particular?  Mark: I certainly didn’t. One of the things and in retrospect looking back at it, people ask, why didn’t you ban them back then? We banned Kogan’s app from our platform, but we didn’t ban Cambridge Analytica in 2015, why did we do that? It actually turns out in our understanding of the situation, they weren’t using any of Facebook’s services back then. They weren’t an advertiser, although they went on to become one in the 2016 elections. And I don’t think they were administering tools and they didn’t build an app directly. So, they were not really a player that we had been paying attention to. So, that’s the history there.  Carlos Hernandez, Expansion: Hi Mark. You mentioned one of the main important things about Facebook is people… and users’ understanding of the platform. Do you have any plans to let users know how their data is being used? Not just on Facebook but also on Instagram and other platforms that you are responsible for?  Mark: I think we need to do a better job of explaining principles that the service operates under, but the main principles are, you have control over everything you put on the service, and most of the content Facebook knows about you it because you chose to share that content with your friends and put it on your profile. And we’re going to use data to make those services better, whether that’s ranking News Feed, or ads, or search, or helping you connect with people through people you may know, but we’re never going to sell your information. And I think if we can get to a place where we can communicate that in a way that people can understand it, then I think we have a shot of distilling this down to something, to a simpler thing, but that’s certainly not something we have succeeded at doing historically.  Kurt Wagner, Recode: Hey Mark. There’s been the whole #deletefacebook thing that went around a few weeks ago, there’s been advertisers that have that they are either going to pull advertising money or pull their pages down altogether. I’m wondering if on the back end, have you seen any actual change in usage from users or change in ad buys from advertisers over the past couple of weeks as result of all this?  Mark: I don’t think there has been any meaningful impact we’ve observed. But, look, it’s not good. I don’t want anyone to be unhappy with our services or what we do as a company. So, even if we can’t really measure a change and the usage of a product, or the business or anything like that, it still speaks to people feeling like this is a massive breach of trust and that we have a lot of work to do to repair that.  Fernando Santillanes, Grupo Milenio: Hi Mark. Thank you very much for doing this. There’s a lot of concern in Mexico about the fake news. People say that associating with media to [downrank] these fake articles is not enough. We are in an election year, here in Mexico. People are worried that there are a lot of apps, a lot of means, that a candidate won’t manipulate the information. What do you say to Mexicans this election year, here almost all internet users have a Facebook account and that they want to see a more active Facebook position to detect and [downrank] fake news?  Mark: This is important. Let me say two things. The first is that 2018 is going to be an important year for protecting election integrity around the world. There’s the Mexican presidential election, there are big presidential elections in India and Brazil, as well as Pakistan and Hungary and a number of other countries, and the US midterms, of course, too. Second, let me talk about how we’re fighting fake news across the board. Right, because there are really three different types of activity that require different strategies for fighting them, so you can understand all of what we’re doing here. The three basic categories, are: economic actors — basically spammers — the second are governments, trying to interfere in elections — that’s a security issue — the third is just polarization and some kind of lack of truthfulness in what you’ve described as the media and in terms of people who are legitimately trying to get the opinion they believe out there. So let’s look at each of these briefly.  So for economic actors, these are folks like the Macedonian trolls who we identified with AI tools leading up to the Alabama special election. What these folks are doing is just an economic game, it’s not ideological at all. They come up with the most sensational thing they can, try to push it out to social media and the internet to try to get you to click on it so that they can make money on ads. So, we make it so that the economics stop working for them, and they’ll move on to something else. I mean, these are the same type of people who were sending you Viagra emails in the 90s. Right, we can attack it both sides: on the revenue side we can make it so that they can’t run on the Facebook ad network, and that’s important because now they don’t make as much money on that because the ad network works well for folks. On the distribution side, we make it so that as we detect the stuff that it gets less distribution on News Feed. So now we just make it so that it’s less worth it for them, so that they kind of go and do other stuff and we’re seeing that that’s working.  The next category are these national security type issues. So that’s the Russian election interference, and instead of treating it like spammers, you treat it as a security issue. In order to solve that, what we need to do is identify these bad actors. It’s actually less about content, because some of the stuff would’ve been legitimate speech had someone who is not a bad actor been doing it, but people are setting up these large networks of fake accounts, like the IRA had done, and what we need to do is just track that really carefully in order to be able to remove it from Facebook entirely. What we’re seeing is the IRA and organizations like that, are morphing — whether they’re media organizations or sanctioned news organizations in Russia, are that when we investigate this closely over time, we’re able to prove are completely owned, controlled and operated by the IRA, we take that down and treat it as a security issue.  The third category is about legitimate media. And there, I think there are a few different strategies. The first is doing more fact checking. To your question, in Mexico, we recently launched our fact-checking initiative in Mexico, specifically, leading up to the election, that’s an important thing to do. We find that even though the fact-checkers aren’t checking millions of things a day, we can show them the highest volume things and that can both be used to show a useful signal on the product, and help inform rankings to flag to people if it’s a hoax. But then even beyond that, for stuff that’s not just broad hoaxes, there’s still a big polarization issue, which is that often even if someone isn’t false, they’re kind of cherry-picking facts to tell one side of the story, and the aggregate picture ends up not being true even if the specific facts within it might be. And there, the work that you need to do is about promoting broadly-trusted journalism. The folks who people across society are going to take the full picture and show, and do a fair and thorough job. That’s the News Feed change we made there, which I think we’ve gotten relatively good feedback from people using Facebook on that change and the quality of what they’re seeing.  So, those three streams, I think that if we can do a good job on each of those, we’ll make a big dent in the problem. Not only for the Mexican election this year, but across the world and that’s basically the road-map that we’re executing.  Casey Newton, The Verge: With respect to some of the measures you’re putting into place to protect election integrity, and reduce fake news that you just talked about, how are you evaluating the effectiveness of the changes you’re making and how will you communicate regarding any wins and losses in run up to and the aftermath of the next election?  Mark: One of the big things that we’re working on now is a major transparency effort to be able to share the prevalence of different types of bad content. Right now, one of the big issues that we see — you know a lot of the debate around things like fake news or hate speech happens through anecdotes. People see something that is bad, that shouldn’t be allowed on the service, and they call us out on it. And frankly, they are right, it shouldn’t be there, and we should do a better job of taking that down. What I think is missing from the debate today is the prevalence of the different categories of bad content. Whether it’s fake news, and all the different kinds therein, hate speech, bullying, terror content. All of the things that I think we would all agree are bad and that we want to drive down. The most important thing though there is to make sure that the numbers we put out are accurate. We wouldn’t be doing anyone a favor by putting out numbers, then coming back a quarter later and saying hey we messed this up. Part of the point of transparency is both to inform the public debate and to build trust. And if we have to go back and restate those because we got it wrong, then I think the calculation internally is that it’s much better to take a little longer and make sure we’re accurate then to put something out that might be wrong. I [believe] that’s going to end up being way we should be held accountable and measured by the public. I think it will help create more informed debates. And my hope over time is that the playbook and scorecard that we put out will also be followed by other internet platforms, so that way there can be a standard measure across the industry about how to measure these important issues.  Barbara Ortutay, AP: Hi. Thank you. So one of the things that you’ve addressed recently, some of the ways malicious actors are misusing Facebook. So I’m wondering what are you doing differently now to prevent things from happening, and not just respond after the fact? You know, will this be built into your new product launches that you have to think about and, if possible, [misuse] right away once the product is out?  Mark: Yeah. I think going forward, I think a lot of the new product development has already internalized this perspective of the broader responsibility that we need to take to make sure our tools are used well. I can give you a few examples across different work that we’re doing. But right now, if you take the election integrity work for example, in 2016 we were behind where we wanted to be. We had a more traditional view of the security threats. We expected Russia and other countries to try do to phishing, and traditional kind of security exploits, but not necessarily kind of misinformation campaign that they did. We were behind. That was a really big miss. So now we want to make sure that we’re not behind again. As I mentioned my opening remarks earlier — since then there was the French election, the German election, you know last fall there was the Alabama special election and we’ve been proactively developing AI tools to detect trolls who are spreading fake news or foreign interference. In the French election and Alabama election, we were able to take down thousands of fake accounts. So that’s an example of proactive work we’re doing to get ahead, which gives me confidence that on that kind of specific issue, around election integrity, we’re making progress. It’s not that there’s no bad content out there. I don’t want to ever promise that we’re going to find everything or that we’ve beaten the enemies into submission. They are still employed, they still have their jobs. We need to strengthen our system. But across the different products and things we’re building, I do think that we’re starting to internalize a lot more that we have this broader responsibility.  Last thing I’ll say on this, I wish that I could snap my fingers and in three or six months have solved all of these issues. But I just think the reality is, given how complex Facebook is and how many systems there we need to rethink our relationship with people and our responsibility there across every single part of what we do. I do think this is a multi-year effort. It doesn’t mean its not going to get better, every month. I think it will continue to get better. I think part of the good news is that we’ve really started ramping up on this a year ago or more. So we’re not getting a cold start, we’re probably a year into a massive three-year push. My hope is that by the end of this year, we’ll have turned the corner on a lot of these issues and people see that things are getting a lot better. But these are just big issues, this is a big shift for us to take a lot more responsibility for how each of the tools are used, not just the developer platform, not just fake news, not just elections, but everything. And its going to take some time. And we’re committed to getting that right and we’re going to invest and keep on working until we do.  Thank you all for joining today. What we announced today were some of changes that we need to make. We’re going to keep on looking for things, we’re going to keep on finding more, and we’ll update you then. Thanks for joining and talking to us about this. We look forward to keeping you updated on our progress.","data/Facebook newsroom/Hard Questions.txt"
"March 7, 2018  Introducing Video Chat in Messenger Lite  Today we’re thrilled to introduce video chat in Messenger Lite, a slimmed down version of Messenger for Android that offers the core features of the app while giving everyone the opportunity to stay connected to their friends and family, intended for people with older Android devices and/or slower Internet connections.  Video chats are an expected and essential part of everyday communication in today’s messaging experience. Chatting face-to-face live is perfect for those moments when you want to see and hear the voices of people you care about most – whether you’re wishing someone a happy birthday, you have some great news to share, or you spontaneously want to catch up on the day.  Video chats are incredibly popular for people who use the Messenger core app. In 2017, there were 17 billion video chats in Messenger, twice as many video chats compared to 2016. Now people who use Messenger Lite can have the same rich and expressive face-to-face conversations as those who use the core Messenger app, no matter which technology they use or have access to.  Messenger Lite offers core messaging capabilities like sending text, photos, links, and audio calls to people with either Messenger Lite or Messenger. Messenger Lite is under 10MB, making it fast to install and quick to start up.  Here’s how it works: to get started, make sure you have the latest version of Messenger Lite. Open an existing conversation or find the person you’d like to chat with in your contact list, then tap the video icon on the upper right corner of the screen. You can also upgrade an audio call to a video chat while still in the call by tapping the video icon in the bottom right corner of the screen.   We’re excited to bring you the ability to have face-to-face conversations with those who matter the most to you, wherever they are. We’re rolling this out starting today and look forward to hearing what you think.","data/Facebook newsroom/Introducing Video Chat in Messenger Lite.txt"
"March 28, 2018  It’s Time to Make Our Privacy Tools Easier to Find  By Erin Egan, VP and Chief Privacy Officer, Policy and Ashlie Beringer, VP and Deputy General Counsel  Last week showed how much more work we need to do to enforce our policies and help people understand how Facebook works and the choices they have over their data. We’ve heard loud and clear that privacy settings and other important tools are too hard to find and that we must do more to keep people informed. So in addition to Mark Zuckerberg’s announcements last week – cracking down on abuse of the Facebook platform, strengthening our policies, and making it easier for people to revoke apps’ ability to use your data – we’re taking additional steps in the coming weeks to put people more in control of their privacy. Most of these updates have been in the works for some time, but the events of the past several days underscore their importance.  Making Data Settings and Tools Easier to Find  Controls that are easier to find and use. We’ve redesigned our entire settings menu on mobile devices from top to bottom to make things easier to find. Instead of having settings spread across nearly 20 different screens, they’re now accessible from a single place. We’ve also cleaned up outdated settings so it’s clear what information can and can’t be shared with apps.   A comparison of the old settings menu (left) and new settings menu (right).  New Privacy Shortcuts menu. People have also told us that information about privacy, security, and ads should be much easier to find. The new Privacy Shortcuts is a menu where you can control your data in just a few taps, with clearer explanations of how our controls work. The experience is now clearer, more visual, and easy-to-find. From here you can:  Make your account more secure: You can add more layers of protection to your account, like two-factor authentication. If you turn this on and someone tries to log into your account from a device we don’t recognize, you’ll be asked to confirm whether it was you. Control your personal information: You can review what you’ve shared and delete it if you want to. This includes posts you’ve shared or reacted to, friend requests you’ve sent, and things you’ve searched for on Facebook. Control the ads you see: You can manage the information we use to show you ads. Ad preferences explains how ads work and the options you have. Manage who sees your posts and profile information: You own what you share on Facebook, and you can manage things like who sees your posts and the information you choose to include on your profile.   Tools to find, download and delete your Facebook data. It’s one thing to have a policy explaining what data we collect and use, but it’s even more useful when people see and manage their own information. Some people want to delete things they’ve shared in the past, while others are just curious about the information Facebook has. So we’re introducing Access Your Information – a secure way for people to access and manage their information, such as posts, reactions, comments, and things you’ve searched for. You can go here to delete anything from your timeline or profile that you no longer want on Facebook.  We’re also making it easier to download the data you’ve shared with Facebook – it’s your data, after all. You can download a secure copy and even move it to another service. This includes photos you’ve uploaded, contacts you’ve added to your account, posts on your timeline, and more.    The Road Ahead  It’s also our responsibility to tell you how we collect and use your data in language that’s detailed, but also easy to understand. In the coming weeks, we’ll be proposing updates to Facebook’s terms of service that include our commitments to people. We’ll also update our data policy to better spell out what data we collect and how we use it. These updates are about transparency – not about gaining new rights to collect, use, or share data.  We’ve worked with regulators, legislators and privacy experts on these tools and updates. We’ll have more to share in the coming weeks, including updates on the measures Mark shared last week.","data/Facebook newsroom/It’s Time to Make Our Privacy Tools Easier to Find.txt"
"April 6, 2018  Making Ads and Pages More Transparent By Rob Goldman, VP, Ads and Alex Himel, VP, Local & Pages  We believe that when you visit a Page or see an ad on Facebook it should be clear who it’s coming from. We also think it’s important for people to be able to see the other ads a Page is running, even if they’re not directed at you. That’s why today we’re announcing important changes to the way we manage ads and Pages on Facebook as well as Instagram. These are designed to increase transparency and accountability, as well as prevent election interference.  Increased Transparency and Accountability for Electoral and Issue Ads  Last October, we announced that only authorized advertisers will be able to run electoral ads on Facebook or Instagram. And today, we’re extending that requirement to anyone that wants to show “issue ads” — like political topics that are being debated across the country. We are working with third parties to develop a list of key issues, which we will refine over time. To get authorized by Facebook, advertisers will need to confirm their identity and location. Advertisers will be prohibited from running political ads — electoral or issue-based — until they are authorized.  In addition, these ads will be clearly labeled in the top left corner as “Political Ad.” Next to it we will show “paid for by” information. We started testing the authorization process this week, and people will begin seeing the label and additional information in the US later this spring.   We’re also investing in artificial intelligence and adding more people to help find advertisers that should have gone through the authorization process but did not. We realize we won’t catch every ad that should be labeled, and we encourage anyone who sees an unlabeled political ad to report it. People can do this by tapping the three dots at the top right corner of the ad and selecting “Report Ad.”  View Ads and Searchable Political Archive  In Canada, we’ve been testing a new feature called view ads that lets you see the ads a Page is running — even if they are not in your News Feed. This applies to all advertiser Pages on Facebook — not just Pages running political ads. We plan to launch view ads globally in June.  In June we also plan to release a public, searchable political ads archive. This will contain all ads with the “Political Ad” label, and will show the image and text, as well as additional information like the amount spent and demographic audience information for each ad.  Increased Authenticity and Transparency for Pages  Today, we’re also announcing that people who manage Pages with large numbers of followers will need to be verified. Those who manage large Pages that do not clear the process will no longer be able to post. This will make it much harder for people to administer a Page using a fake account, which is strictly against our policies. We will also show you additional context about Pages to effectively assess their content. For example, you can see whether a Page has changed its name.  Why We’re Doing This  We know we were slow to pick-up foreign interference in the 2016 US elections. Today’s updates are designed to prevent future abuse in elections — and to help ensure you have the information that you need to assess political and issue ads, as well as content on Pages. By increasing transparency around ads and Pages on Facebook, we can increase accountability for advertisers — improving our service for everyone.","data/Facebook newsroom/Making Ads and Pages More Transparent.txt"
"March 19, 2018  Pursuing Forensic Audits to Investigate Cambridge Analytica Claims Update on March 19, 2018, 3:25 PM PT: Independent forensic auditors from Stroz Friedberg were on site at Cambridge Analytica’s London office this evening. At the request of the UK Information Commissioner’s Office, which has announced it is pursuing a warrant to conduct its own on-site investigation, the Stroz Friedberg auditors stood down.  Originally published March 19, 2018, 11:40 AM PT: We have hired a digital forensics firm, Stroz Friedberg, to conduct a comprehensive audit of Cambridge Analytica. Cambridge Analytica has agreed to comply and afford the firm complete access to their servers and systems. We have approached the other parties involved — Christopher Wylie and Aleksandr Kogan — and asked them to submit to an audit as well. Mr. Kogan has given his verbal agreement to do so. Mr. Wylie thus far has declined.  This is part of a comprehensive internal and external review that we are conducting to determine the accuracy of the claims that the Facebook data in question still exists. This is data Cambridge Analytica, SCL, Mr. Wylie, and Mr. Kogan certified to Facebook had been destroyed. If this data still exists, it would be a grave violation of Facebook’s policies and an unacceptable violation of trust and the commitments these groups made.  We are moving aggressively to determine the accuracy of these claims. We remain committed to vigorously enforcing our policies to protect people’s information. We also want to be clear that today when developers create apps that ask for certain information from people, we conduct a robust review to identify potential policy violations and to assess whether the app has a legitimate use for the data. We actually reject a significant number of apps through this process. Kogan’s app would not be permitted access to detailed friends’ data today.","data/Facebook newsroom/Pursuing Forensic Audits to Investigate Cambridge Analytica Claims.txt"
"March 16, 2018  Suspending Cambridge Analytica and SCL Group from Facebook By Paul Grewal, VP & Deputy General Counsel  Update on March 17, 2018, 9:50 AM PT: The claim that this is a data breach is completely false. Aleksandr Kogan requested and gained access to information from users who chose to sign up to his app, and everyone involved gave their consent. People knowingly provided their information, no systems were infiltrated, and no passwords or sensitive pieces of information were stolen or hacked.  Originally published on March 16, 2018: We are suspending Strategic Communication Laboratories (SCL), including their political data analytics firm, Cambridge Analytica, from Facebook. Given the public prominence of this organization, we want to take a moment to explain how we came to this decision and why.  We Maintain Strict Standards and Policies  Protecting people’s information is at the heart of everything we do, and we require the same from people who operate apps on Facebook. In 2015, we learned that a psychology professor at the University of Cambridge named Dr. Aleksandr Kogan lied to us and violated our Platform Policies by passing data from an app that was using Facebook Login to SCL/Cambridge Analytica, a firm that does political, government and military work around the globe. He also passed that data to Christopher Wylie of Eunoia Technologies, Inc.  Like all app developers, Kogan requested and gained access to information from people after they chose to download his app. His app, “thisisyourdigitallife,” offered a personality prediction, and billed itself on Facebook as “a research app used by psychologists.” Approximately 270,000 people downloaded the app. In so doing, they gave their consent for Kogan to access information such as the city they set on their profile, or content they had liked, as well as more limited information about friends who had their privacy settings set to allow it.  Although Kogan gained access to this information in a legitimate way and through the proper channels that governed all developers on Facebook at that time, he did not subsequently abide by our rules. By passing information on to a third party, including SCL/Cambridge Analytica and Christopher Wylie of Eunoia Technologies, he violated our platform policies. When we learned of this violation in 2015, we removed his app from Facebook and demanded certifications from Kogan and all parties he had given data to that the information had been destroyed. Cambridge Analytica, Kogan and Wylie all certified to us that they destroyed the data.  Breaking the Rules Leads to Suspension  Several days ago, we received reports that, contrary to the certifications we were given, not all data was deleted. We are moving aggressively to determine the accuracy of these claims. If true, this is another unacceptable violation of trust and the commitments they made. We are suspending SCL/Cambridge Analytica, Wylie and Kogan from Facebook, pending further information.  We are committed to vigorously enforcing our policies to protect people’s information. We will take whatever steps are required to see that this happens. We will take legal action if necessary to hold them responsible and accountable for any unlawful behavior.  How Things Have Changed  We are constantly working to improve the safety and experience of everyone on Facebook. In the past five years, we have made significant improvements in our ability to detect and prevent violations by app developers. Now all apps requesting detailed user information go through our App Review process, which requires developers to justify the data they’re looking to collect and how they’re going to use it – before they’re allowed to even ask people for it.  In 2014, after hearing feedback from the Facebook community, we made an update to ensure that each person decides what information they want to share about themselves, including their friend list. This is just one of the many ways we give people the tools to control their experience. Before you decide to use an app, you can review the permissions the developer is requesting and choose which information to share. You can manage or revoke those permissions at any time.  On an ongoing basis, we also do a variety of manual and automated checks to ensure compliance with our policies and a positive experience for users. These include steps such as random audits of existing apps along with the regular and proactive monitoring of the fastest growing apps.  We enforce our policies in a variety of ways — from working with developers to fix the problem, to suspending developers from our platform, to pursuing litigation.","data/Facebook newsroom/Suspending Cambridge Analytica and SCL Group from Facebook.txt"
"March 19, 2018  Testing New Tools and Experiences for Creators By Fidji Simo, VP of Product and Sibyl Goldman, Director of Entertainment Partnerships  Every day on Facebook, creators use video to bring their communities together around common passions.  We’ve been working closely with creators to understand what they need to be successful on Facebook. To support them, we’re focused on three areas: helping them engage and grow their community, manage their presence, and build a business on Facebook. We’re already investing deeply in these areas — like with the Facebook Creator app and Facebook for Creators site we introduced last year. In the coming months, we’ll be testing a range of new tools for creators. We’re still in an experimental phase and will be iterating on these tests in the coming months, but we want to share a preview of what we’re working on.  Engaging and Growing Creators’ Communities We’re committed to giving creators great ways to share and build connections with their community. For example, creators like Sebastian Villalobos use Live and Live With to talk in real time with their fans. Markian shares moments from his day using Facebook Stories, and many creators have Groups where fans can more deeply engage with each other – like Tessa Netting’s superfan Group. We’re also exploring ways to bring people together around video, like with Watch Party.  As we continue to help creators build relationships with their audiences, we’re going to make it easier to identify and connect with their most passionate fans. We’re starting a new test that highlights a creator’s top fans by displaying a badge next to their names and adding their name to a leaderboard of highly engaged fans. We’ll identify top fans based on how often they comment, share, react or watch a creator’s content, as well as the creator’s interactions with the fan and other criteria. Fans will opt into this experience, and they can turn off the feature at any time. This test will start with a small set of creators in the coming weeks.  Managing Creators’ Presence on Facebook We need to make it easy for creators to manage their presence on Facebook. We’ve always offered detailed Page Insights to help people understand how their posts perform, and last year we rolled out our Facebook for Creators website and Creator app on iOS globally. Thousands of creators including Belly Full, Wuz Good, Juanma Salazar, Archana’s Kitchen, and LeJuan James are using the Creator app to get insights about their audience and more easily talk and share with fans. We’re working to bring the Facebook Creator app to Android soon.  We are always looking for more opportunities to help creators manage their content on Facebook, and are now testing a content rights management tool designed specifically for creators. This new version of our Rights Manager tool includes simplified and more automated capabilities, which we hope will make it easier for people to use the system and get recognition for their work.  Building a Business on Facebook As creators spend more time making content and engaging with their fans, they want to be able to earn money for their work. We plan to offer a range of monetization options to serve the wide range of creators at various stages of their journeys. Today any creator can use branded content to extend their existing brand deals onto Facebook. We’ve also made Ad Breaks available to a small set of creators creating shows for Watch. Creators who would like to make and monetize shows for Watch can register their interest here.  In the coming months, we’re going to explore two new monetization features for creators. First is a tool that helps advertisers and creators easily connect for branded content opportunities on Facebook. Creators participating in the test can set up a portfolio highlighting their area of expertise, and advertisers can search and find creators to collaborate on compelling branded content campaigns. Additionally, we’ll be testing a way for fans to become a supporter of the creators they love. Fans will have the option to support the creator with a monthly payment in exchange for perks like exclusive content and a badge highlighting their status as a supporter. We’ll start testing with a small set of creators so we can gather feedback from them and their fans before expanding. (Note that testing this feature means the Facebook app will now include an “In App Purchase” label in the App Store and Google Play.)  Collaborative Development with Creators We’re excited about all of the things we’ll be building this year and know there’s a lot more yet to do. To help us learn and build the things creators want and need, we will be piloting a product testing program with a small group of creators, which will include many of the tools mentioned above. Creators in this program will get access to early test features and will spend time with our team to provide frequent and direct feedback. The goal of this collaborative product test is to help us more quickly iterate and build experiences that will benefit our entire creator community.  We encourage creators to join the Facebook for Creators community at facebook.com/creators/join to be considered for product testing opportunities and be notified about when new features become available.","data/Facebook newsroom/Testing New Tools and Experiences for Creators.txt"
"April 4, 2018  We’re Making Our Terms and Data Policy Clearer, Without New Rights to Use Your Data on Facebook By Erin Egan, VP and Chief Privacy Officer, Policy and Ashlie Beringer, VP and Deputy General Counsel  It’s important to show people in black and white how our products work – it’s one of the ways people can make informed decisions about their privacy. So we’re proposing updates to our terms of service that include our commitments to everyone using Facebook. We explain the services we offer in language that’s easier to read. We’re also updating our data policy to better spell out what data we collect and how we use it in Facebook, Instagram, Messenger and other products.  These updates are about making things clearer. We’re not asking for new rights to collect, use or share your data on Facebook. We’re also not changing any of the privacy choices you’ve made in the past. Here are a few examples of what you’ll find:  New features and tools: We’re providing information on recently introduced features. Since we last updated our terms or data policy three years ago, you can now buy and sell items on Marketplace, start a fundraiser for a cause you care about, share Live and 360 video, and add creative effects to your photos. Personalized experience: Everyone’s experience on Facebook is unique, and we’re providing more information on how this works. We explain how we use data and why it’s needed to customize the posts and ads you see, as well as the Groups, friends and Pages we suggest. What we share: We will never sell your information to anyone. We have a responsibility to keep people’s information safe and secure, and we impose strict restrictions on how our partners can use and disclose data. We explain all of the circumstances where we share information and make our commitments to people more clear. Advertising: You have control over the ads you see, and we don’t share your information with advertisers. Our data policy explains more about how we decide which ads to show you. One company: Facebook is part of the same company as WhatsApp and Oculus, and we explain how we share services, infrastructure and information. We also make clear that Facebook is the corporate entity that provides the Messenger and Instagram services, which now all use the same data policy. Your experience isn’t changing with any of these products. Device information: People have asked to see all the information we collect from the devices they use and whether we respect the settings on your mobile device (the short answer: we do). We’ve also added more specific information about the information we collect when you sync your contacts from some of our products, including call and SMS history, which people have recently asked about. Addressing harmful behavior: We better explain how we combat abuse and investigate suspicious activity, including by analyzing the content people share. For the next seven days, you’ll be able to provide your feedback on the terms and data policy. Once finalized, we’ll publish these documents and ask you to agree to them on Facebook, along with information about the choices you have over your privacy.","data/Facebook newsroom/We’re Making Our Terms and Data Policy Clearer, Without New Rights to Use Your Data on Facebook.txt"
"March 7, 2018  When Women Lead, Everyone Progresses  By Maxine Williams, Global Chief Diversity Officer  March 8 is International Women’s Day, a day that celebrates the many contributions that women around the world make to their communities every day.  In 2017, International Women’s Day was the #1 most talked-about moment of the year*. It was a moment that rallied the world around empowering women, and that was just the beginning of mounting energy for women’s movements that shows no signs of slowing down in 2018.  Every day we see women using Facebook Groups, Pages and Fundraisers to truly make a positive impact in their communities:  Maria, leads Supergirls, a group of nearly 90,000 women in Israel who share the same challenges in life: career, family and identity. Supergirls is a home for sharing deep secrets, asking personal questions or having a shoulder to cry on, and has held more than 100 community meetings to have social impact not only online, but in person. Angel works for the Alameda County Fair, a 20-day, 150-year-old fair that began in 1859 in downtown Oakland as a floral event. With no previous marketing experience but a passion for the fair, Angel took a job in the marketing department. She started a Facebook Page, and from there Angel has grown their following to 100,000, increased ticket sales, and helped to hire 25 additional employees. For her birthday last November, Natalie asked her friends and family to help support Women and Children First: The Center Against Family Violence, Central Arkansas’s largest Domestic Violence Shelter offering emergency shelter, support services and advocacy. She saw such great momentum, that she surpassed her fundraising goal and raised enough to help two women leave abusive relationships and be safe. On March 8, we are helping celebrate women like these who are leading the way in their communities:  First, the Credit Her campaign will spotlight women from the past and present — such as Billie Jean King and Big Mama Thornton — to whom we want to help give credit for their incredible contributions. This will be available on facebook.com/facebook on March 8.  Second, on mobile devices, people will have the opportunity to show their support through cards, photo frames or themed backgrounds for text posts, all designed to inspire people to express themselves on this day. Look for a message in News Feed on March 8, or visit facebook.com/iwd.   Finally, #SheMeansBusiness, a program established by Facebook in 2016 to support women-owned businesses, is launching Community Finder. This tool will give female entrepreneurs the power to connect with each other and share questions, advice, resources and support to help them grow their businesses. We’re also hosting Open Door events at Facebook offices around the world where women can participate in workshops, discussions and networking opportunities. Visit shemeansbusiness.fb.com for more information.   We hope everyone will join in on the moment and celebrate the women in their lives — whether they contributed to your success, lifted you up, or inspired you and others in your community.  *Based on year in review methodology, measuring growth in Facebook conversation","data/Facebook newsroom/When Women Lead Everyone Progresses.txt"
"April 3, 2018  With 360 Degree Photos and HD Quality Video, Messenger Gets Even More Visual  By Sean Kelly & Hagen Green, Product Managers, Messenger  Visuals are the best way to add delightful expression and meaningful emotions to your chats. Earlier this year we shared that the ability to send photos, videos, stickers and GIFs in Messenger is extremely popular and now we are continuing to make these features richer, sharper, and better than ever. That’s why today, we are introducing the ability to send 360 degree photos in Messenger.  Amazing 360 degree photos, and panoramic photos, will give you the ability to share more immersive views of your world – from stunning landscapes, to that coveted ocean view from your hotel room, or the way your new apartment looks – the world is your oyster now in Messenger.  That’s not all. On the heels of our high resolution photo news introduced last fall, we’re also launching the ability to share high definition quality videos straight to Messenger. Many smartphones capture videos with HD resolution, and now people on Messenger can send and receive HD quality, 720p videos straight from their camera roll.  To try out these new features, first update your Messenger app to make sure you have the latest version.  For 360 degree photos in Messenger, simply set your phone camera to panorama and snap a photo or capture a 360 degree photo using a 360 photo app or camera. Then share it in Messenger as you would a normal photo. From there, we’ll convert it to an immersive, envy-inducing photo that your friends and loved ones can experience on mobile by tapping and dragging the photo or by moving their phone, and on Messenger.com by clicking and dragging.  To share HD videos, you can either share a video saved on your phone, from your newsfeed, or even share a video from one message thread to another.  Both 360 degree photos and HD videos are easy to identify in Messenger. You will see a compass icon on the right-hand side of a panoramic photo. The videos will also be easily identifiable with a HD or SD marker. If you’d like, you can change the quality right from the marker on the lower right side when in full screen mode.  360 degree photos in Messenger are available all over the world on both iOS and Android. HD quality videos are available in Australia, Belgium, Canada, Denmark, Finland, France, Hong Kong, Japan, Netherlands, Norway, Romania, Singapore, South Korea, Sweden, Switzerland, Taiwan, UK and the US on iOS and Android.  We hope you make your conversations and connections on Messenger even more extraordinary with these new features!","data/Facebook newsroom/With 360 Degree Photos and HD Quality Video, Messenger Gets Even More Visual.txt"
"March 21, 2018  You’re in Charge: Messenger Group Chats Are Now Better Than Ever  By Drew Moxon, Messenger Product Manager  Bringing groups of people together is powerful, and at Messenger, we’re always thinking about how we can improve group chats – especially since 2.5 million new groups were created on Messenger every day last year. Today we’re excited to start rolling out new, widely-requested Messenger features that make your group chat experience more robust and seamless by giving you more control – whether you’re planning a weekend trip with friends, chatting about a new episode of your favorite show with likeminded fans, or catching up with your family.  Admin privileges allow you to approve new members before they join your group chat. This is especially helpful in large group chats with people you may not yet be connected to, like when you’re planning a friend’s surprise birthday party with different groups of friends. Admins also have the ability to remove members if needed, and promote or demote any other person in the group chat as an admin.   The great thing about admin privileges in Messenger is they work in the background; if your group chat doesn’t need that level of control, it won’t get in the way of your group messaging. You’ll have the option to decide if you’d like admin approval for approving new members, but this preference is off by default in your group chat settings. Admin privileges in Workplace Chat are also rolling out today, learn more here.  We’re also making it easier to add new people to group chats with joinable links. Anyone in a group chat can create a custom invite link and share it with someone they’d like to join the conversation. People who tap the link will either be added to the group automatically if approvals are off, or will be added once the admin has approved the request.  By chatting with up to 250 people in a group at a time, group chats are fun, useful, and seamless at the same time. And admin privileges and joinable links are just a few of the great group chat features in Messenger:  Last year we introduced several new features including @mentions, making it easy to jump right back in to the conversation to answer someone’s question or to provide a response We also introduced reactions, giving you an option to quickly show acknowledgement or express how you feel in an easy way with an emoji Group payments make it easy to get paid back whether you’re splitting a restaurant bill or chipping in for a group gift. There are also fun ways to customize group chats, making conversations more delightful with custom emoji, nicknames, a photo, and text color. You can also have realtime voice and video chats in groups with up to 50 people at a time, and now you can add friends and family to your in-progress voice and video chats without having to interrupt the conversation, making sure no one misses out.  Messenger is a great way to connect to the groups of people you care about most – helping you spend time together online or even better, making plans to spend time together in real life. We’re looking forward to hearing what you think as we roll out these new group chat features!","data/Facebook newsroom/You’re in Charge.txt"
